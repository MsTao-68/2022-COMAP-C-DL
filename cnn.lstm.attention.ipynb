{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dd6e3b-2b48-488b-bae6-57e9376de7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-09-11</th>\n",
       "      <td>621.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-12</th>\n",
       "      <td>609.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-13</th>\n",
       "      <td>610.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-14</th>\n",
       "      <td>608.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-15</th>\n",
       "      <td>610.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Value\n",
       "Date              \n",
       "2016-09-11  621.65\n",
       "2016-09-12  609.67\n",
       "2016-09-13  610.92\n",
       "2016-09-14  608.82\n",
       "2016-09-15  610.38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "df2 = pd.read_csv('LBMA-GOLD.csv',header=0,index_col=0,parse_dates = True)\n",
    "df1 = pd.read_csv('BCHAIN-MKPRU.csv',header=0, index_col=0,parse_dates=True)\n",
    "df1.reset_index().drop('Date',axis=1,inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1ee5f0-4f80-41dd-b572-f3bd36999f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1278, 1) (548, 1)\n"
     ]
    }
   ],
   "source": [
    "data_train =df1.iloc[:int(df1.shape[0] * 0.7), :]\n",
    "data_test = df1.iloc[int(df1.shape[0] * 0.7):, :]\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3672017f-7451-42a3-a91e-3461584bb602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(feature_range=(-1, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1b920c-0b05-4eb3-b40f-9e7956163c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99708325],\n",
       "       [-0.99835067],\n",
       "       [-0.99821842],\n",
       "       ...,\n",
       "       [-0.21232941],\n",
       "       [-0.22369596],\n",
       "       [-0.22861328]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb2dbbe-6268-4ad0-aacf-bf082d70e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1273, 5, 1) (1273,) (543, 5, 1) (543,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "# from keras.optimizers import Adam\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "adam = adam_v2.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "output_dim = 1\n",
    "batch_size = 256 #每轮训练模型时，样本的数量\n",
    "epochs = 60 #训练60轮次\n",
    "seq_len = 5\n",
    "hidden_size = 128\n",
    "\n",
    "\n",
    "TIME_STEPS = 5\n",
    "INPUT_DIM = 1\n",
    "\n",
    "lstm_units = 64\n",
    "X_train = np.array([data_train[i : i + seq_len, :] for i in range(data_train.shape[0] - seq_len)])\n",
    "y_train = np.array([data_train[i + seq_len, 0] for i in range(data_train.shape[0]- seq_len)])\n",
    "X_test = np.array([data_test[i : i + seq_len, :] for i in range(data_test.shape[0]- seq_len)])\n",
    "y_test = np.array([data_test[i + seq_len, 0] for i in range(data_test.shape[0] - seq_len)])\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4dd4f9f-cd65-4104-9d8d-b6f39d44b464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(TIME_STEPS, INPUT_DIM))\n",
    "#drop1 = Dropout(0.3)(inputs)\n",
    "\n",
    "x = Conv1D(filters = 64, kernel_size = 1, activation = 'relu')(inputs)  #, padding = 'same'\n",
    "#x = Conv1D(filters=128, kernel_size=5, activation='relu')(output1)#embedded_sequences\n",
    "x = MaxPooling1D(pool_size = 5)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3cf41a5-42d9-4eaf-aa0d-01a242dd0a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(None, 128)\n"
     ]
    }
   ],
   "source": [
    "lstm_out = Bidirectional(LSTM(lstm_units, activation='relu'), name='bilstm')(x)\n",
    "#lstm_out = LSTM(lstm_units,activation='relu')(x)\n",
    "print(lstm_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48ba50ae-4911-4b75-9b20-20ea939b0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# from keras.engine.topology import Layer\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "import numpy as np\n",
    "from keras import initializers\n",
    "# Attention GRU network  未用     \n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializers.get('normal')\n",
    "        #self.input_spec = [InputSpec(ndim=3)]\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==128\n",
    "        #self.W = self.init((input_shape[-1],1))\n",
    "        self.W = self.init((input_shape[-1],))\n",
    "        #self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.tanh(K.dot(x, self.W))\n",
    "        \n",
    "        ai = K.exp(eij)\n",
    "        weights = ai/K.sum(ai, axis=1).dimshuffle(0,'x')\n",
    "        \n",
    "        weighted_input = x*weights.dimshuffle(0,1,'x')\n",
    "        return weighted_input.sum(axis=1)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3511d4c5-edc9-401f-ae33-bbb9a303adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, merge\n",
    "from keras import layers\n",
    "# ATTENTION PART STARTS HERE\n",
    "attention_probs = Dense(128, activation='sigmoid', name='attention_vec')(lstm_out)\n",
    "#attention_mul=layers.merge([stm_out,attention_probs], output_shape],mode='concat',concat_axis=1))\n",
    "attention_mul =Multiply()([lstm_out, attention_probs])\n",
    "#attention_mul = merge([lstm_out, attention_probs],output_shape=32, name='attention_mul', mode='mul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b153b91-0828-4684-9ad9-6e97d97ce625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 5, 64)        128         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 1, 64)        0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 64)        0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " bilstm (Bidirectional)         (None, 128)          66048       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " attention_vec (Dense)          (None, 128)          16512       ['bilstm[0][0]']                 \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 128)          0           ['bilstm[0][0]',                 \n",
      "                                                                  'attention_vec[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            129         ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,817\n",
      "Trainable params: 82,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "#output = Dense(10, activation='sigmoid')(drop2)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4a798-067a-405d-9dd0-d3785b9720c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=False)\n",
    "y_pred = model.predict(X_test)\n",
    "print('MSE Train loss:', model.evaluate(X_train, y_train, batch_size=batch_size))\n",
    "print('MSE Test loss:', model.evaluate(X_test, y_test, batch_size=batch_size))\n",
    "plt.plot(y_test, label='test')\n",
    "plt.plot(y_pred, label='pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9050919-97c1-4be7-bc90-7c66f891ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"./pollution.csv\")\n",
    "df = df.drop(['date','wnd_dir'], axis = 1)\n",
    "train_size = int(len(df)*0.8)\n",
    "train = df.iloc[:train_size,:]\n",
    "test = df.iloc[train_size:,:]\n",
    "#train, test = train_test_split(df, test_size=0.1)\n",
    "print(\"len(train):\",len(train))\n",
    "print(\"len(test):\",len(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
